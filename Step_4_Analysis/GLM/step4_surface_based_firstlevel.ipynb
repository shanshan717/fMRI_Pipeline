{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# **如何进行GLM 一阶分析 (基于surface空间)**\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于surface空间的GLM一阶分析代码，以NARPS数据集中的被试数据为例进行演示。\n",
    "\n",
    "本教程展示了如何在大脑皮层表面空间中进行fMRI数据的一阶GLM分析。\n",
    "\n",
    "**参考资料：**\n",
    "- [Nilearn Surface-based GLM Analysis](https://nilearn.github.io/dev/auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html)\n",
    "- [NARPS数据集描述](https://www.nature.com/articles/s41586-020-2314-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import nibabel as nb\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, run_glm\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "\n",
    "# 用于计算不同条件之间的对比\n",
    "from itertools import combinations \n",
    "\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数，根据头动参数（帧位移与六个方向的运动参数）识别头动过大的时间点并删除\n",
    "def motion_controlled_event_timetable(event_table, fd_data, six_absolute_motion, TR, FD_thr, ab_motion_thr):\n",
    "    # 检测超出帧位移（FD）阈值的时间点\n",
    "    out_motion_detect = fd_data.to_numpy().flatten() > FD_thr\n",
    "    out_motion_index = np.where(out_motion_detect)[0]\n",
    "    # 检测超过绝对运动阈值的时间点\n",
    "    six_motion_ex = np.where(np.any(np.abs(six_absolute_motion) > ab_motion_thr, axis=1))[0]\n",
    "    \n",
    "    # 将运动时间点通过乘以 TR 转换为实际时间\n",
    "    out_motion_time = np.array([])\n",
    "    if len(out_motion_index) > 0:\n",
    "        out_motion_time = (out_motion_index + 1) * TR\n",
    "    if len(six_motion_ex) > 0:\n",
    "        six_motion_time = (six_motion_ex + 1) * TR\n",
    "        out_motion_time = np.concatenate((out_motion_time, six_motion_time), axis=0)\n",
    "        out_motion_time = np.unique(out_motion_time)\n",
    "    \n",
    "    # 为事件表添加一个新列'time_end'，计算每个事件的结束时间\n",
    "    # 使用lambda函数计算：结束时间 = 开始时间(onset) + 持续时间(duration)\n",
    "    tmp_timetable = event_table.assign(time_end=lambda dataframe: dataframe['onset'] + dataframe['duration'])\n",
    "    tmp_timetable = tmp_timetable.reset_index(drop=True)\n",
    "    \n",
    "    # 标记运动超过阈值的时间点\n",
    "    block_time_judge = np.zeros(tmp_timetable.shape[0])\n",
    "    block_time_in = np.zeros(tmp_timetable.shape[0])\n",
    "    try:\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            for i in out_motion_time:\n",
    "                time_judge_0 = (i <= tmp_timetable.loc[n_time, 'time_end'])\n",
    "                block_time_judge[n_time] += time_judge_0\n",
    "                time_judge_1 = (i <= tmp_timetable.loc[n_time, 'time_end']) and (i >= tmp_timetable.loc[n_time, 'onset'])\n",
    "                block_time_in[n_time] += time_judge_1\n",
    "            \n",
    "        tmp_timetable = tmp_timetable.assign(\n",
    "            time_delete=block_time_judge * TR,\n",
    "            delete_time_inblock=block_time_in\n",
    "        )\n",
    "        tmp_timetable.loc[:, 'duration'] = tmp_timetable['duration'] - tmp_timetable['delete_time_inblock'] * TR\n",
    "        \n",
    "        # 调整起始时间 (onset) 并重新计算结束时间\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            if n_time != 0:\n",
    "                tmp_timetable.loc[n_time, 'onset'] = tmp_timetable.loc[n_time, 'onset'] - tmp_timetable.loc[n_time, 'time_delete']\n",
    "            tmp_timetable.loc[n_time, 'time_end'] = tmp_timetable.loc[n_time, 'onset'] + tmp_timetable.loc[n_time, 'duration']\n",
    "    except Exception as e:\n",
    "        print(\"Error in motion_controlled_event_timetable:\", e)\n",
    "        out_motion_time = False\n",
    "        tmp_timetable = event_table\n",
    "    return [tmp_timetable, out_motion_time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数，删除对应运动时间点的 GIFTI 时间点\n",
    "def correct_motion_for_giidata(motion_corrected_path, subname, run, task_file_L, task_file_R, data_L_path, data_R_path, TR, out_motion_time):\n",
    "    motion_corrected_subfolder = op.join(motion_corrected_path, subname)\n",
    "    if not os.path.exists(motion_corrected_subfolder):\n",
    "        os.makedirs(motion_corrected_subfolder)\n",
    "    corrected_gii_file_L = op.join(motion_corrected_subfolder, subname + task_file_L)\n",
    "    corrected_gii_file_R = op.join(motion_corrected_subfolder, subname + task_file_R)\n",
    "    \n",
    "    # 加载 GIFTI 数据\n",
    "    data_L = nb.load(data_L_path)\n",
    "    data_R = nb.load(data_R_path)\n",
    "\n",
    "    # 计算需要删除的时间点\n",
    "    timepoints_to_delete = ((out_motion_time / TR).astype(int)) - 1\n",
    "    timepoints_to_keep = np.setdiff1d(np.arange(len(data_L.darrays)), timepoints_to_delete)\n",
    "\n",
    "    # 创建新的 GIFTI 图像，包含选定的时间点\n",
    "    corrected_darrays_L = [data_L.darrays[i] for i in timepoints_to_keep]\n",
    "    corrected_darrays_R = [data_R.darrays[i] for i in timepoints_to_keep]\n",
    "    \n",
    "    corrected_data_L = nb.gifti.GiftiImage(darrays=corrected_darrays_L)\n",
    "    corrected_data_R = nb.gifti.GiftiImage(darrays=corrected_darrays_R)\n",
    "    \n",
    "    # 保存校正后的 GIFTI 数据\n",
    "    nb.save(corrected_data_L, corrected_gii_file_L)\n",
    "    nb.save(corrected_data_R, corrected_gii_file_R)\n",
    "    \n",
    "    return corrected_gii_file_L, corrected_gii_file_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置根目录和数据路径\n",
    "rootdir = '/Volumes/ss/ds001734'\n",
    "# 可以根据需要修改被试列表(sublist)和run列表(runs)\n",
    "# 这里只使用Narps数据中的第一个被试，一共是4次run\n",
    "sublist = ['001'] \n",
    "runs = ['01', '02', '03', '04']\n",
    "# task名称，可以根据实际数据修改\n",
    "taskname = 'MGT'\n",
    "# 根据你的数据修改TR时间\n",
    "# 对于公开数据集，TR值通常可以在以下位置找到：\n",
    "# 1. 原始论文的Methods部分\n",
    "# 2. BIDS格式数据的task-*_bold.json文件中的\"RepetitionTime\"字段\n",
    "TR = 1.0  \n",
    "# 设置帧位移和绝对运动阈值，这是绝大多数研究中常用的阈值，你也可以根据实际情况进行调整\n",
    "FD_thr = 0.2  \n",
    "ab_motion_thr = 3  \n",
    "\n",
    "# 设置输出路径\n",
    "out_path = op.join(rootdir, 'derivatives', 'first_level_model_corrected_gii')\n",
    "motion_corrected_path = op.join(rootdir, 'derivatives', 'motion_corrected_data_gii')\n",
    "\n",
    "# 设置是否进行头动校正（删除头动过大的时间点）\n",
    "# 设置为 False 可避免删除由于头动造成的运动伪影较大的时间帧\n",
    "do_motion_exclusion = False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/78rqxlxn4pz_rsb5_31xvh340000gn/T/ipykernel_29135/1985284099.py:96: UserWarning: The following unexpected columns in events data will be ignored: gain, loss, RT\n",
      "  design_matrix = make_first_level_design_matrix(\n",
      "/Users/ss/miniconda3/envs/fmri_pipeline/lib/python3.12/site-packages/nilearn/glm/_utils.py:207: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 01 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_accept for sub-001, run 01 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 01 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 01 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject_zmap.R.func.gii\n",
      "Contrast NoResp for sub-001, run 01 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_NoResp_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_NoResp_zmap.R.func.gii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/78rqxlxn4pz_rsb5_31xvh340000gn/T/ipykernel_29135/1985284099.py:96: UserWarning: The following unexpected columns in events data will be ignored: gain, loss, RT\n",
      "  design_matrix = make_first_level_design_matrix(\n",
      "/Users/ss/miniconda3/envs/fmri_pipeline/lib/python3.12/site-packages/nilearn/glm/_utils.py:207: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast strongly_accept for sub-001, run 02 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_accept for sub-001, run 02 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 02 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 02 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_reject_zmap.R.func.gii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/78rqxlxn4pz_rsb5_31xvh340000gn/T/ipykernel_29135/1985284099.py:96: UserWarning: The following unexpected columns in events data will be ignored: gain, loss, RT\n",
      "  design_matrix = make_first_level_design_matrix(\n",
      "/Users/ss/miniconda3/envs/fmri_pipeline/lib/python3.12/site-packages/nilearn/glm/_utils.py:207: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 03 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_accept for sub-001, run 03 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 03 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 03 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_reject_zmap.R.func.gii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/78rqxlxn4pz_rsb5_31xvh340000gn/T/ipykernel_29135/1985284099.py:96: UserWarning: The following unexpected columns in events data will be ignored: gain, loss, RT\n",
      "  design_matrix = make_first_level_design_matrix(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 04 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_accept for sub-001, run 04 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 04 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 04 completed and saved to /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_reject_zmap.L.func.gii and /Volumes/ss/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_reject_zmap.R.func.gii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ss/miniconda3/envs/fmri_pipeline/lib/python3.12/site-packages/nilearn/glm/_utils.py:207: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    }
   ],
   "source": [
    "# 主要代码：GLM一阶分析的核心循环\n",
    "# 遍历每个被试和每个run，进行独立的一阶分析\n",
    "\n",
    "for sub in sublist:\n",
    "    subname = 'sub-' + sub\n",
    "    subeventdir = op.join(rootdir, subname, 'func')\n",
    "    subimagedir = op.join(rootdir, 'derivatives', 'fmriprep', subname, 'func')\n",
    "    for run in runs:\n",
    "        sub_event_file = op.join(subeventdir, f'{subname}_task-{taskname}_run-{run}_events.tsv')\n",
    "        sub_gii_file_L = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-fsaverage5.L.func.gii')\n",
    "        sub_gii_file_R = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-fsaverage5.R.func.gii')\n",
    "        sub_motioninfo_file = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_confounds.tsv')\n",
    "\n",
    "        # 检查所需文件是否存在\n",
    "        # 如果缺少任何文件，则跳过该被试和该run\n",
    "        if not (os.path.exists(sub_event_file) and os.path.exists(sub_gii_file_L) and os.path.exists(sub_gii_file_R) and os.path.exists(sub_motioninfo_file)):\n",
    "            print(f\"Missing files for {subname}, run {run}\")\n",
    "            continue\n",
    "\n",
    "        # 读取事件文件数据\n",
    "        event_data = pd.read_csv(sub_event_file, sep='\\t')\n",
    "        # 将'participant_response' 重命名为'trial_type'\n",
    "        if 'participant_response' in event_data.columns:\n",
    "            event_data.rename(columns={'participant_response': 'trial_type'}, inplace=True)\n",
    "        else:\n",
    "            print(f\"'participant_response' column not found in {sub_event_file}\")\n",
    "            continue\n",
    "\n",
    "        # 读取confounds文件，包含帧位移和六个方向的头动参数\n",
    "        confounds = pd.read_csv(sub_motioninfo_file, sep='\\t')\n",
    "        # 处理缺失值\n",
    "        confounds = confounds.fillna(0)\n",
    "\n",
    "        # 获取帧位移（FD）数据\n",
    "        if 'FramewiseDisplacement' in confounds.columns:\n",
    "            fd = confounds[['FramewiseDisplacement']]\n",
    "        elif 'framewise_displacement' in confounds.columns:\n",
    "            fd = confounds[['framewise_displacement']]\n",
    "        else:\n",
    "            print(f\"FD column not found in {sub_motioninfo_file}\")\n",
    "            continue\n",
    "\n",
    "        # 获取六个方向的头动参数数据\n",
    "        motion_params = confounds[['X', 'Y', 'Z', 'RotX', 'RotY', 'RotZ']]\n",
    "\n",
    "        # 头动校正\n",
    "        # 如果设置了 do_motion_exclusion 为 True，则进行头动校正\n",
    "        # 这将删除头动过大的时间点，并返回校正后的事件数据\n",
    "        if do_motion_exclusion:\n",
    "            [event_data_corrected, out_motion_time] = motion_controlled_event_timetable(event_data, fd, motion_params, TR, FD_thr, ab_motion_thr)\n",
    "            # 保存校正后的 events 数据\n",
    "            out_sub_path = op.join(out_path, subname)\n",
    "            if not os.path.exists(out_sub_path):\n",
    "                os.makedirs(out_sub_path)\n",
    "            event_out_file = op.join(out_sub_path, f'{subname}_task-{taskname}_run-{run}_events_corrected.tsv')\n",
    "            event_data_corrected.to_csv(event_out_file, sep='\\t', index=False)\n",
    "            # 校正 GIFTI 数据\n",
    "            if not isinstance(out_motion_time, bool):\n",
    "                task_file_L = f'_task-{taskname}_run-{run}_bold_space-fsaverage5.L.func.gii'\n",
    "                task_file_R = f'_task-{taskname}_run-{run}_bold_space-fsaverage5.R.func.gii'\n",
    "                corrected_gii_file_L, corrected_gii_file_R = correct_motion_for_giidata(\n",
    "                    motion_corrected_path, subname, run, task_file_L, task_file_R, \n",
    "                    sub_gii_file_L, sub_gii_file_R, TR, out_motion_time\n",
    "                )\n",
    "                data_L = nb.load(corrected_gii_file_L)\n",
    "                data_R = nb.load(corrected_gii_file_R)\n",
    "                # 计算需要删除的时间点\n",
    "                timepoints_to_delete = ((out_motion_time / TR).astype('int64')) - 1\n",
    "                motion_params_corrected = motion_params.drop(motion_params.index[timepoints_to_delete]).reset_index(drop=True)\n",
    "            else:\n",
    "                data_L = nb.load(sub_gii_file_L)\n",
    "                data_R = nb.load(sub_gii_file_R)\n",
    "                motion_params_corrected = motion_params\n",
    "                event_data_corrected = event_data\n",
    "        else:\n",
    "            event_data_corrected = event_data\n",
    "            data_L = nb.load(sub_gii_file_L)\n",
    "            data_R = nb.load(sub_gii_file_R)\n",
    "            motion_params_corrected = motion_params\n",
    "\n",
    "        # 将左右半球的数据合并为一个矩阵\n",
    "        # todo: len(data_L.darrays) 选择len(data_R.darrays)是不是也可以\n",
    "        # todo: n_vertices_L 和 n_vertices_R 的值应该是一样的\n",
    "        n_timepoints = len(data_L.darrays)\n",
    "        print(n_timepoints)\n",
    "        n_vertices_L = data_L.darrays[0].data.shape[0]\n",
    "        print(n_vertices_L)\n",
    "        n_vertices_R = data_R.darrays[0].data.shape[0]\n",
    "        print(n_vertices_R)\n",
    "\n",
    "        # 构建一个二维零矩阵(data_matrix)，行数为n_timepoints，列数为左右脑半球的顶点数之和\n",
    "        data_matrix = np.zeros((n_timepoints, n_vertices_L + n_vertices_R))\n",
    "        print(data_matrix.shape)\n",
    "        for t in range(n_timepoints):\n",
    "            data_L_t = data_L.darrays[t].data\n",
    "            data_R_t = data_R.darrays[t].data\n",
    "            data_matrix[t, :n_vertices_L] = data_L_t\n",
    "            data_matrix[t, n_vertices_L:] = data_R_t\n",
    "\n",
    "        # 手动构建设计矩阵\n",
    "        frame_times = TR * (np.arange(n_timepoints))\n",
    "        design_matrix = make_first_level_design_matrix(\n",
    "            frame_times,\n",
    "            event_data_corrected,\n",
    "            drift_model='polynomial',\n",
    "            drift_order=3,\n",
    "            # 添加头动参数\n",
    "            add_regs=motion_params_corrected,\n",
    "            add_reg_names=motion_params_corrected.columns,\n",
    "            hrf_model='spm'\n",
    "        )\n",
    "\n",
    "        # 进行 GLM 分析\n",
    "        # 不要转置 data_matrix; Y 应该具有形状 (n_samples, n_voxels)\n",
    "        # run_glm 返回 labels 和 estimates\n",
    "        labels, estimates = run_glm(data_matrix, design_matrix.values)\n",
    "\n",
    "        # 定义对比条件\n",
    "        conditions = event_data_corrected['trial_type'].unique()\n",
    "        design_columns = design_matrix.columns\n",
    "\n",
    "        # 为每个条件创建一个对比向量\n",
    "        contrasts = {}\n",
    "        for cond in conditions:\n",
    "            # 对应该条件的列\n",
    "            cond_vector = np.array([1 if cond == col else 0 for col in design_columns])\n",
    "            contrasts[cond] = cond_vector\n",
    "\n",
    "        # 创建输出目录\n",
    "        out_sub_path = op.join(out_path, subname)\n",
    "        stats_results_path = op.join(out_sub_path, 'stats_results', f'run-{run}')\n",
    "        if not os.path.exists(stats_results_path):\n",
    "            os.makedirs(stats_results_path)\n",
    "\n",
    "        # 计算每个条件与基线的对比\n",
    "        for contrast_id, contrast_val in contrasts.items():\n",
    "            contrast = compute_contrast(labels, estimates, contrast_val)\n",
    "            # 计算 Z-map\n",
    "            z_map = contrast.z_score()\n",
    "             \n",
    "            # z_map 的形状为 (n_voxels,)，即一维数组包含所有体素/顶点的Z值\n",
    "            # 将 z_map 重新分割为左右半球\n",
    "            z_map_L = z_map[:n_vertices_L]\n",
    "            z_map_R = z_map[n_vertices_L:]\n",
    "\n",
    "            # 创建 GIFTI 数据数组\n",
    "            z_map_L_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_L))\n",
    "            z_map_R_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_R))\n",
    "\n",
    "            # 创建 GIFTI 图像\n",
    "            z_map_img_L = nb.gifti.GiftiImage(darrays=[z_map_L_darray])\n",
    "            z_map_img_R = nb.gifti.GiftiImage(darrays=[z_map_R_darray])\n",
    "\n",
    "            # 保存 GIFTI 图像文件\n",
    "            z_map_file_L = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.L.func.gii')\n",
    "            z_map_file_R = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.R.func.gii')\n",
    "            nb.save(z_map_img_L, z_map_file_L)\n",
    "            nb.save(z_map_img_R, z_map_file_R)\n",
    "\n",
    "            print(f\"Contrast {contrast_id} for {subname}, run {run} completed and saved to {z_map_file_L} and {z_map_file_R}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
