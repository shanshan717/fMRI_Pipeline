{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# **如何进行GLM 一阶分析**\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程以 NARPS 数据为例，基于 [Nilearn 工具包](https://nilearn.github.io/stable/auto_examples/04_glm_first_level/index.html)，详细介绍一阶分析的基本流程。\n",
    "\n",
    "本节介绍参数调制（Parametric Modulation）的分析策略，首先会介绍什么是Parametric Modulation，其次会以narps数据为例进行具体代码展示。\n",
    "\n",
    "对于基于 GIfTI（.gii）格式的表层空间分析内容，本教程不作详细展开，感兴趣的读者可参考以下补充代码文件：\n",
    "\n",
    "1. Step_4_Analysis/GLM/step4_surface_based_firstlevel.py\n",
    "2. Step_4_Analysis/GLM/step4_surface_based_firstlevel_modulation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **什么是Parametric Modulation**\n",
    "- **Step 1: events文件的读取与预处理**\n",
    "- **Step 2: 基于confounds文件的运动校正**\n",
    "- **Step 3: 使用 FirstLevelModel 进行建模与估计**\n",
    "- **Step 4: 设置条件对比（contrast）并导出结果**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 什么是Parametric Modulation\n",
    "\n",
    "在大多数 fMRI 实验分析中，我们使用**GLM**来估计每种实验条件（如视觉刺激、听觉刺激等）对大脑中每个体素的 BOLD 信号影响。这种方法会为每个条件生成一个参数估计值（*β*值），代表这个条件平均引发的 BOLD 响应。\n",
    "\n",
    "但在一些实验中，我们不仅关心是否出现了某个刺激，更关心这个刺激在不同特征强度下是否会引起不同的大脑反应。这就是参数调制（Parametric Modulation）的用武之地。\n",
    "\n",
    "假设你有一个任务，其中呈现一束光，每次光的亮度不同。如果你记录了每次光亮度的数值，你就可以检查：BOLD 信号是否随着亮度增加而增强？\n",
    "\n",
    "这个“信号是否随着某种变量变化而变化”的过程，就是Parametric Modulation。\n",
    "\n",
    "> https://andysbrainbook.readthedocs.io/en/latest/PM/PM_Overview.html\n",
    "\n",
    "> Sabrina M. Tom et al. ,The Neural Basis of Loss Aversion in Decision-Making Under Risk.Science315,515-518(2007).DOI:10.1126/science.1134239\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import nibabel as nb\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "# 用于计算不同条件之间的对比\n",
    "from itertools import combinations \n",
    "from nilearn.plotting import plot_design_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数，根据头动参数（帧位移与六个方向的运动参数）识别头动过大的时间点并删除\n",
    "def motion_controlled_event_timetable(event_table, fd_data, six_absolute_motion, TR, FD_thr, ab_motion_thr):\n",
    "    # 检测超出帧位移（FD）阈值的时间点\n",
    "    out_motion_detect = fd_data.to_numpy()[:] > FD_thr\n",
    "    out_motion_index = np.where(out_motion_detect == True)\n",
    "    \n",
    "    # 检测超过绝对运动阈值的时间点\n",
    "    six_motion_ex = np.where(np.sum((six_absolute_motion > ab_motion_thr) == True, 1) > 0)\n",
    "    \n",
    "    # 将运动时间点通过乘以 TR 转换为实际时间\n",
    "    out_motion_time = np.array([])\n",
    "    if len(out_motion_index[0]) > 0:\n",
    "        out_motion_time = (out_motion_index[0][:] + 1) * TR\n",
    "    if len(six_motion_ex[0]) > 0:\n",
    "        six_motion_time = (six_motion_ex[0] + 1) * TR\n",
    "        out_motion_time = np.concatenate((out_motion_time, six_motion_time), axis=0)\n",
    "        out_motion_time = np.unique(out_motion_time)\n",
    "    \n",
    "    # 为事件表添加一个新列'time_end'，计算每个事件的结束时间\n",
    "    # 使用lambda函数计算：结束时间 = 开始时间(onset) + 持续时间(duration)\n",
    "    tmp_timetable = event_table.assign(time_end=lambda dataframe: dataframe['onset'] + dataframe['duration'])\n",
    "    tmp_timetable = tmp_timetable.reset_index(drop=True)\n",
    "    \n",
    "    # 标记运动超过阈值的时间点\n",
    "    block_time_judge = np.zeros(tmp_timetable.shape[0])\n",
    "    block_time_in = np.zeros(tmp_timetable.shape[0])\n",
    "    try:\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            for i in out_motion_time:\n",
    "                time_judge_0 = (i <= tmp_timetable.loc[n_time, 'time_end'])\n",
    "                block_time_judge[n_time] += time_judge_0\n",
    "                time_judge_1 = (i <= tmp_timetable.loc[n_time, 'time_end']) * (i >= tmp_timetable.loc[n_time, 'onset'])\n",
    "                block_time_in[n_time] += time_judge_1\n",
    "            \n",
    "        tmp_timetable = tmp_timetable.assign(\n",
    "            time_delete=block_time_judge * TR,\n",
    "            delete_time_inblock=block_time_in\n",
    "        )\n",
    "        tmp_timetable.loc[:, 'duration'] = tmp_timetable['duration'] - tmp_timetable['delete_time_inblock'] * TR\n",
    "        \n",
    "        # 调整起始时间 (onset) 并重新计算结束时间\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            if n_time != 0:\n",
    "                tmp_timetable.loc[n_time, 'onset'] = tmp_timetable.loc[n_time, 'onset'] - tmp_timetable.loc[n_time, 'time_delete']\n",
    "            tmp_timetable.loc[n_time, 'time_end'] = tmp_timetable.loc[n_time, 'onset'] + tmp_timetable.loc[n_time, 'duration']\n",
    "    except Exception as e:\n",
    "        print(\"Error in motion_controlled_event_timetable:\", e)\n",
    "        out_motion_time = False\n",
    "        tmp_timetable = event_table\n",
    "    return [tmp_timetable, out_motion_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数，删除对应运动时间点的 NIfTI 时间点\n",
    "def correct_motion_for_niidata(motion_corrected_path, subname, run, task_file, nii_data, TR, out_motion_time):\n",
    "    motion_corrected_subfolder = op.join(motion_corrected_path, subname)\n",
    "    if not os.path.exists(motion_corrected_subfolder):\n",
    "        os.makedirs(motion_corrected_subfolder)\n",
    "    motion_corrected_nii = op.join(motion_corrected_subfolder, subname + task_file)\n",
    "    niidata = nb.load(nii_data)\n",
    "    timepoints_to_delete = ((out_motion_time / TR).astype('int64')) - 1\n",
    "    motion_corrected_data = np.delete(niidata.get_fdata(), timepoints_to_delete, axis=3)\n",
    "    motion_corrected_nii_data = nb.Nifti1Image(motion_corrected_data, header=niidata.header, affine=niidata.affine)\n",
    "    motion_corrected_nii_data.header.set_data_dtype(np.int16)\n",
    "    nb.save(motion_corrected_nii_data, motion_corrected_nii)\n",
    "    return motion_corrected_nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据根目录\n",
    "rootdir = '/Volumes/ss/ds001734'\n",
    "# 可以根据需要修改被试列表(sublist)和run列表(runs)\n",
    "# 这里只使用Narps数据中的第一个被试，一共是4次run\n",
    "sublist = ['001']  \n",
    "runs = ['01', '02', '03', '04']\n",
    "# task名称，可以根据实际数据修改\n",
    "taskname = 'MGT'\n",
    "# 根据你的数据修改TR时间\n",
    "# 对于公开数据集，TR值通常可以在以下位置找到：\n",
    "# 1. 原始论文的Methods部分\n",
    "# 2. BIDS格式数据的task-*_bold.json文件中的\"RepetitionTime\"字段\n",
    "TR = 1.0  \n",
    "# 设置帧位移和绝对运动阈值，这是绝大多数研究中常用的阈值，你也可以根据实际情况进行调整\n",
    "FD_thr = 0.2  \n",
    "ab_motion_thr = 3  \n",
    "\n",
    "# 设置输出路径\n",
    "out_path = op.join(rootdir, 'derivatives', 'first_level_model_corrected_nii')\n",
    "motion_corrected_path = op.join(rootdir, 'derivatives', 'motion_corrected_data_nii')\n",
    "\n",
    "# 设置是否进行头动校正（删除头动过大的时间点）\n",
    "# 设置为 False 可避免删除由于头动造成的运动伪影较大的时间帧\n",
    "do_motion_exclusion = False  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际的 GLM 分析中，我们通常不会只处理一个被试，因此使用循环结构可以大幅提高分析效率。\n",
    "\n",
    "不过，如果你希望深入理解循环代码中每一行的含义，以及各个变量的具体内容，可以在每行代码下方添加 `print()` 语句，或者单独创建一个代码块，打印变量的输出结果来进行查看。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以`subeventdir` 为例\n",
    "# 取消下面代码的注释，运行即可查看`subeventdir`变量的输出结果是什么\n",
    "# subeventdir\n",
    "\n",
    "# 或者使用print语句查看，取消注释运行查看输出结果即可\n",
    "# print(f\"events文件的路径：{subeventdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于nilearn中 'FirstLevelModel' 各参数的介绍，可以参考：\n",
    "\n",
    "> https://nilearn.github.io/dev/auto_examples/04_glm_first_level/plot_first_level_details.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要代码\n",
    "for sub in sublist:\n",
    "    subname = 'sub-' + sub\n",
    "    subeventdir = op.join(rootdir, subname, 'func')\n",
    "    subimagedir = op.join(rootdir, 'derivatives', 'fmriprep', subname, 'func')\n",
    "    for run in runs:\n",
    "        sub_event_file = op.join(subeventdir, f'{subname}_task-{taskname}_run-{run}_events.tsv')\n",
    "        sub_niidata_file = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "        sub_motioninfo_file = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_confounds.tsv')\n",
    "\n",
    "        # Check if all necessary files exist\n",
    "        if not (os.path.exists(sub_event_file) and os.path.exists(sub_niidata_file) and os.path.exists(sub_motioninfo_file)):\n",
    "            print(f\"Missing files for {subname}, run {run}\")\n",
    "            continue\n",
    "\n",
    "        # Load event data\n",
    "        event_data = pd.read_csv(sub_event_file, sep='\\t')\n",
    "        # Rename 'participant_response' to 'trial_type', here we use the condition based coding for each trial\n",
    "        # make trial_type based on whether the participant_response equal to 'NoResp'\n",
    "        event_data['trial_type'] = event_data['participant_response'].apply(\n",
    "            lambda x: 'NoResp' if x == 'NoResp' else 'Resp'\n",
    "        )\n",
    "\n",
    "        # make sure that gain as modulation effect\n",
    "        if 'gain' not in event_data.columns:\n",
    "            print(f\"'gain' column not found in {sub_event_file}\")\n",
    "            continue\n",
    "        else:\n",
    "            event_data.rename(columns={'gain': 'modulation'}, inplace=True)\n",
    "        # Load motion parameters data\n",
    "        confounds = pd.read_csv(sub_motioninfo_file, sep='\\t')\n",
    "        # Handle missing values\n",
    "        confounds = confounds.fillna(0)\n",
    "\n",
    "        # Get framewise displacement (FD) data\n",
    "        if 'FramewiseDisplacement' in confounds.columns:\n",
    "            fd = confounds[['FramewiseDisplacement']]\n",
    "        elif 'framewise_displacement' in confounds.columns:\n",
    "            fd = confounds[['framewise_displacement']]\n",
    "        else:\n",
    "            print(f\"FD column not found in {sub_motioninfo_file}\")\n",
    "            continue\n",
    "\n",
    "        # Get six motion parameters\n",
    "        motion_params = confounds[['X', 'Y', 'Z', 'RotX', 'RotY', 'RotZ']]\n",
    "\n",
    "        # Motion correction\n",
    "        if do_motion_exclusion:\n",
    "            [event_data_corrected, out_motion_time] = motion_controlled_event_timetable(event_data, fd, motion_params, TR, FD_thr, ab_motion_thr)\n",
    "            # Save corrected event data\n",
    "            out_sub_path = op.join(out_path, subname)\n",
    "            if not os.path.exists(out_sub_path):\n",
    "                os.makedirs(out_sub_path)\n",
    "            event_out_file = op.join(out_sub_path, f'{subname}_task-{taskname}_run-{run}_events_corrected.tsv')\n",
    "            event_data_corrected.to_csv(event_out_file, sep='\\t', index=False)\n",
    "            # Correct NIfTI data\n",
    "            if not isinstance(out_motion_time, bool):\n",
    "                task_file = f'_task-{taskname}_run-{run}_bold_space-MNI152NLin2009cAsym_preproc.nii.gz'\n",
    "                corrected_nii_file = correct_motion_for_niidata(motion_corrected_path, subname, run, task_file, sub_niidata_file, TR, out_motion_time)\n",
    "                fmri_img = nb.load(corrected_nii_file)\n",
    "                # Adjust motion parameters\n",
    "                timepoints_to_delete = ((out_motion_time / TR).astype('int64')) - 1\n",
    "                motion_params_corrected = motion_params.drop(motion_params.index[timepoints_to_delete]).reset_index(drop=True)\n",
    "            else:\n",
    "                fmri_img = nb.load(sub_niidata_file)\n",
    "                motion_params_corrected = motion_params\n",
    "                event_data_corrected = event_data\n",
    "        else:\n",
    "            event_data_corrected = event_data\n",
    "            fmri_img = nb.load(sub_niidata_file)\n",
    "            motion_params_corrected = motion_params\n",
    "            \n",
    "        frame_times = (\n",
    "            np.arange(fmri_img.shape[3]) * TR\n",
    "        )  # here are the corresponding frame times\n",
    "        \n",
    "        unmodulated_matrix = event_data_corrected[['onset', 'duration', 'trial_type']]\n",
    "        modulated_matrix = event_data_corrected[['onset', 'duration', 'trial_type','modulation']]\n",
    "        \n",
    "        GLM_matrix_unmodulated = make_first_level_design_matrix(\n",
    "            frame_times,\n",
    "            unmodulated_matrix,\n",
    "            drift_model=\"polynomial\",\n",
    "            drift_order=3,\n",
    "            hrf_model=\"spm + derivative\",\n",
    "        )\n",
    "        \n",
    "        GLM_matrix_modulated = make_first_level_design_matrix(\n",
    "            frame_times,\n",
    "            modulated_matrix,\n",
    "            drift_model=\"polynomial\",\n",
    "            drift_order=3,\n",
    "            hrf_model=\"spm + derivative\",\n",
    "        )\n",
    "        # Let's compare two design matrix\n",
    "        fig, (ax1, ax2) = plt.subplots(\n",
    "            figsize=(10, 6), nrows=1, ncols=2, constrained_layout=True\n",
    "        )\n",
    "\n",
    "        plot_design_matrix(GLM_matrix_unmodulated, axes=ax1,rescale=False)\n",
    "        ax1.set_title(\"Event design matrix\", fontsize=12)\n",
    "        plot_design_matrix(GLM_matrix_modulated, axes=ax2,rescale=False)\n",
    "        ax2.set_title(\"Modulated Event design matrix\", fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "        # Perform first-level GLM analysis\n",
    "        fmri_glm = FirstLevelModel(\n",
    "            t_r=TR,\n",
    "            noise_model='ar1',\n",
    "            hrf_model='spm + derivative',\n",
    "            drift_model='polynomial',# the desired drift model for the design matrices\n",
    "            drift_order = 3,  # Adjust the drift order as needed\n",
    "            high_pass=1./128,  # Adjust the high-pass filter as needed\n",
    "            signal_scaling=False,  # Whether to scale the signal\n",
    "            minimize_memory=False\n",
    "        )\n",
    "        # we use the GLM_matrix_modulated\n",
    "        fmri_glm = fmri_glm.fit(\n",
    "            fmri_img,\n",
    "            events=modulated_matrix,\n",
    "            confounds=motion_params_corrected\n",
    "        )\n",
    "\n",
    "        # Define contrasts\n",
    "        # Assuming 'trial_type' column contains condition names\n",
    "        conditions = event_data_corrected['trial_type'].unique()\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "        # Create contrasts for each condition\n",
    "        contrasts = {}\n",
    "        for cond in conditions:\n",
    "            # The columns corresponding to the condition\n",
    "            cond_vector = np.array([1 if c == cond else 0 for c in design_matrix.columns])\n",
    "            contrasts[cond] = cond_vector\n",
    "        # Compute contrasts for each condition vs baseline\n",
    "        out_sub_path = op.join(out_path, subname)\n",
    "        stats_results_path = op.join(out_sub_path, 'stats_results', f'run-{run}')\n",
    "        if not os.path.exists(stats_results_path):\n",
    "            os.makedirs(stats_results_path)\n",
    "        for contrast_id, contrast_val in contrasts.items():\n",
    "            z_map = fmri_glm.compute_contrast(contrast_val, output_type='z_score')\n",
    "            z_map_file = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.nii.gz')\n",
    "            z_map.to_filename(z_map_file)\n",
    "            print(f\"Contrast {contrast_id} for {subname}, run {run} completed and saved to {z_map_file}\")\n",
    "            # Optionally, plot the contrast map\n",
    "            plot_stat_map(z_map, title=f'{subname} {contrast_id}', display_mode='ortho', threshold=1.0)# unthreshold stats map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
