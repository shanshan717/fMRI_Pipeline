{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# **如何进行GLM 一阶分析 (基于surface空间)**\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import nibabel as nb\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, run_glm\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "from itertools import combinations  # For computing contrasts between conditions\n",
    "\n",
    "# Define the function to adjust the event timetable based on motion information\n",
    "def motion_controlled_event_timetable(event_table, fd_data, six_absolute_motion, TR, FD_thr, ab_motion_thr):\n",
    "    # Detect timepoints where FD exceeds the threshold\n",
    "    out_motion_detect = fd_data.to_numpy().flatten() > FD_thr\n",
    "    out_motion_index = np.where(out_motion_detect)[0]\n",
    "    # Detect timepoints where any of the six motion parameters exceed the absolute motion threshold\n",
    "    six_motion_ex = np.where(np.any(np.abs(six_absolute_motion) > ab_motion_thr, axis=1))[0]\n",
    "    \n",
    "    # Convert motion timepoints to actual time by multiplying with TR\n",
    "    out_motion_time = np.array([])\n",
    "    if len(out_motion_index) > 0:\n",
    "        out_motion_time = (out_motion_index + 1) * TR\n",
    "    if len(six_motion_ex) > 0:\n",
    "        six_motion_time = (six_motion_ex + 1) * TR\n",
    "        out_motion_time = np.concatenate((out_motion_time, six_motion_time), axis=0)\n",
    "        out_motion_time = np.unique(out_motion_time)\n",
    "    \n",
    "    tmp_timetable = event_table.assign(time_end=lambda dataframe: dataframe['onset'] + dataframe['duration'])\n",
    "    tmp_timetable = tmp_timetable.reset_index(drop=True)\n",
    "    \n",
    "    # Mark the timepoints where motion exceeds thresholds\n",
    "    block_time_judge = np.zeros(tmp_timetable.shape[0])\n",
    "    block_time_in = np.zeros(tmp_timetable.shape[0])\n",
    "    try:\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            for i in out_motion_time:\n",
    "                time_judge_0 = (i <= tmp_timetable.loc[n_time, 'time_end'])\n",
    "                block_time_judge[n_time] += time_judge_0\n",
    "                time_judge_1 = (i <= tmp_timetable.loc[n_time, 'time_end']) and (i >= tmp_timetable.loc[n_time, 'onset'])\n",
    "                block_time_in[n_time] += time_judge_1\n",
    "            \n",
    "        tmp_timetable = tmp_timetable.assign(\n",
    "            time_delete=block_time_judge * TR,\n",
    "            delete_time_inblock=block_time_in\n",
    "        )\n",
    "        tmp_timetable.loc[:, 'duration'] = tmp_timetable['duration'] - tmp_timetable['delete_time_inblock'] * TR\n",
    "        \n",
    "        # Adjust onset times and recalculate time_end\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            if n_time != 0:\n",
    "                tmp_timetable.loc[n_time, 'onset'] = tmp_timetable.loc[n_time, 'onset'] - tmp_timetable.loc[n_time, 'time_delete']\n",
    "            tmp_timetable.loc[n_time, 'time_end'] = tmp_timetable.loc[n_time, 'onset'] + tmp_timetable.loc[n_time, 'duration']\n",
    "    except Exception as e:\n",
    "        print(\"Error in motion_controlled_event_timetable:\", e)\n",
    "        out_motion_time = False\n",
    "        tmp_timetable = event_table\n",
    "    return [tmp_timetable, out_motion_time]\n",
    "\n",
    "# Define the function to correct motion in GIFTI data\n",
    "def correct_motion_for_giidata(motion_corrected_path, subname, run, task_file_L, task_file_R, data_L_path, data_R_path, TR, out_motion_time):\n",
    "    motion_corrected_subfolder = op.join(motion_corrected_path, subname)\n",
    "    if not os.path.exists(motion_corrected_subfolder):\n",
    "        os.makedirs(motion_corrected_subfolder)\n",
    "    corrected_gii_file_L = op.join(motion_corrected_subfolder, subname + task_file_L)\n",
    "    corrected_gii_file_R = op.join(motion_corrected_subfolder, subname + task_file_R)\n",
    "    \n",
    "    # Load GIFTI data\n",
    "    data_L = nb.load(data_L_path)\n",
    "    data_R = nb.load(data_R_path)\n",
    "    \n",
    "    # Calculate timepoints to delete\n",
    "    timepoints_to_delete = ((out_motion_time / TR).astype(int)) - 1\n",
    "    timepoints_to_keep = np.setdiff1d(np.arange(len(data_L.darrays)), timepoints_to_delete)\n",
    "    \n",
    "    # Create new GIFTI images with selected timepoints\n",
    "    corrected_darrays_L = [data_L.darrays[i] for i in timepoints_to_keep]\n",
    "    corrected_darrays_R = [data_R.darrays[i] for i in timepoints_to_keep]\n",
    "    \n",
    "    corrected_data_L = nb.gifti.GiftiImage(darrays=corrected_darrays_L)\n",
    "    corrected_data_R = nb.gifti.GiftiImage(darrays=corrected_darrays_R)\n",
    "    \n",
    "    # Save corrected GIFTI data\n",
    "    nb.save(corrected_data_L, corrected_gii_file_L)\n",
    "    nb.save(corrected_data_R, corrected_gii_file_R)\n",
    "    \n",
    "    return corrected_gii_file_L, corrected_gii_file_R\n",
    "\n",
    "# Main code\n",
    "rootdir = '/mnt/d/language_atlas_project/newdata/ds001734'\n",
    "sublist = ['001']  # Add more subjects as needed\n",
    "runs = ['01', '02', '03', '04']\n",
    "taskname = 'MGT'\n",
    "TR = 1.0  # Adjust TR based on your data\n",
    "FD_thr = 0.2  # Framewise displacement threshold\n",
    "ab_motion_thr = 3  # Absolute motion threshold\n",
    "\n",
    "# Output paths\n",
    "out_path = op.join(rootdir, 'derivatives', 'first_level_model_corrected_gii')\n",
    "motion_corrected_path = op.join(rootdir, 'derivatives', 'motion_corrected_data_gii')\n",
    "\n",
    "# Set whether to perform motion exclusion\n",
    "do_motion_exclusion = False  # Set to False to avoid deleting frames due to motion\n",
    "\n",
    "for sub in sublist:\n",
    "    subname = 'sub-' + sub\n",
    "    subeventdir = op.join(rootdir, subname, 'func')\n",
    "    subimagedir = op.join(rootdir, 'derivatives', 'fmriprep', subname, 'func')\n",
    "    for run in runs:\n",
    "        sub_event_file = op.join(subeventdir, f'{subname}_task-{taskname}_run-{run}_events.tsv')\n",
    "        sub_gii_file_L = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-fsaverage5.L.func.gii')\n",
    "        sub_gii_file_R = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-fsaverage5.R.func.gii')\n",
    "        sub_motioninfo_file = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_confounds.tsv')\n",
    "\n",
    "        # Check if all necessary files exist\n",
    "        if not (os.path.exists(sub_event_file) and os.path.exists(sub_gii_file_L) and os.path.exists(sub_gii_file_R) and os.path.exists(sub_motioninfo_file)):\n",
    "            print(f\"Missing files for {subname}, run {run}\")\n",
    "            continue\n",
    "\n",
    "        # Load event data\n",
    "        event_data = pd.read_csv(sub_event_file, sep='\\t')\n",
    "        # Rename 'participant_response' to 'trial_type'\n",
    "        if 'participant_response' in event_data.columns:\n",
    "            event_data.rename(columns={'participant_response': 'trial_type'}, inplace=True)\n",
    "        else:\n",
    "            print(f\"'participant_response' column not found in {sub_event_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load motion parameters data\n",
    "        confounds = pd.read_csv(sub_motioninfo_file, sep='\\t')\n",
    "        # Handle missing values\n",
    "        confounds = confounds.fillna(0)\n",
    "\n",
    "        # Get framewise displacement (FD) data\n",
    "        if 'FramewiseDisplacement' in confounds.columns:\n",
    "            fd = confounds[['FramewiseDisplacement']]\n",
    "        elif 'framewise_displacement' in confounds.columns:\n",
    "            fd = confounds[['framewise_displacement']]\n",
    "        else:\n",
    "            print(f\"FD column not found in {sub_motioninfo_file}\")\n",
    "            continue\n",
    "\n",
    "        # Get six motion parameters\n",
    "        motion_params = confounds[['X', 'Y', 'Z', 'RotX', 'RotY', 'RotZ']]\n",
    "\n",
    "        # Motion correction\n",
    "        if do_motion_exclusion:\n",
    "            [event_data_corrected, out_motion_time] = motion_controlled_event_timetable(event_data, fd, motion_params, TR, FD_thr, ab_motion_thr)\n",
    "            # Save corrected event data\n",
    "            out_sub_path = op.join(out_path, subname)\n",
    "            if not os.path.exists(out_sub_path):\n",
    "                os.makedirs(out_sub_path)\n",
    "            event_out_file = op.join(out_sub_path, f'{subname}_task-{taskname}_run-{run}_events_corrected.tsv')\n",
    "            event_data_corrected.to_csv(event_out_file, sep='\\t', index=False)\n",
    "            # Correct GIFTI data\n",
    "            if not isinstance(out_motion_time, bool):\n",
    "                task_file_L = f'_task-{taskname}_run-{run}_bold_space-fsaverage5.L.func.gii'\n",
    "                task_file_R = f'_task-{taskname}_run-{run}_bold_space-fsaverage5.R.func.gii'\n",
    "                corrected_gii_file_L, corrected_gii_file_R = correct_motion_for_giidata(\n",
    "                    motion_corrected_path, subname, run, task_file_L, task_file_R, \n",
    "                    sub_gii_file_L, sub_gii_file_R, TR, out_motion_time\n",
    "                )\n",
    "                data_L = nb.load(corrected_gii_file_L)\n",
    "                data_R = nb.load(corrected_gii_file_R)\n",
    "                # Adjust motion parameters\n",
    "                timepoints_to_delete = ((out_motion_time / TR).astype('int64')) - 1\n",
    "                motion_params_corrected = motion_params.drop(motion_params.index[timepoints_to_delete]).reset_index(drop=True)\n",
    "            else:\n",
    "                data_L = nb.load(sub_gii_file_L)\n",
    "                data_R = nb.load(sub_gii_file_R)\n",
    "                motion_params_corrected = motion_params\n",
    "                event_data_corrected = event_data\n",
    "        else:\n",
    "            event_data_corrected = event_data\n",
    "            data_L = nb.load(sub_gii_file_L)\n",
    "            data_R = nb.load(sub_gii_file_R)\n",
    "            motion_params_corrected = motion_params\n",
    "\n",
    "        # Concatenate left and right hemisphere data\n",
    "        n_timepoints = len(data_L.darrays)\n",
    "        n_vertices_L = data_L.darrays[0].data.shape[0]\n",
    "        n_vertices_R = data_R.darrays[0].data.shape[0]\n",
    "\n",
    "        # Initialize data matrix\n",
    "        data_matrix = np.zeros((n_timepoints, n_vertices_L + n_vertices_R))\n",
    "        for t in range(n_timepoints):\n",
    "            data_L_t = data_L.darrays[t].data\n",
    "            data_R_t = data_R.darrays[t].data\n",
    "            data_matrix[t, :n_vertices_L] = data_L_t\n",
    "            data_matrix[t, n_vertices_L:] = data_R_t\n",
    "\n",
    "        # Build design matrix\n",
    "        frame_times = TR * (np.arange(n_timepoints))\n",
    "        design_matrix = make_first_level_design_matrix(\n",
    "            frame_times,\n",
    "            event_data_corrected,\n",
    "            drift_model='polynomial',\n",
    "            drift_order=3,\n",
    "            add_regs=motion_params_corrected,\n",
    "            add_reg_names=motion_params_corrected.columns,\n",
    "            hrf_model='spm'\n",
    "        )\n",
    "\n",
    "        # Perform GLM analysis\n",
    "        # Do NOT transpose data_matrix; Y should have shape (n_samples, n_voxels)\n",
    "        labels, estimates = run_glm(data_matrix, design_matrix.values)\n",
    "\n",
    "        # Define contrasts\n",
    "        conditions = event_data_corrected['trial_type'].unique()\n",
    "        design_columns = design_matrix.columns\n",
    "\n",
    "        # Create contrasts for each condition\n",
    "        contrasts = {}\n",
    "        for cond in conditions:\n",
    "            # The columns corresponding to the condition\n",
    "            cond_vector = np.array([1 if cond == col else 0 for col in design_columns])\n",
    "            contrasts[cond] = cond_vector\n",
    "\n",
    "        # Prepare output directories\n",
    "        out_sub_path = op.join(out_path, subname)\n",
    "        stats_results_path = op.join(out_sub_path, 'stats_results', f'run-{run}')\n",
    "        if not os.path.exists(stats_results_path):\n",
    "            os.makedirs(stats_results_path)\n",
    "\n",
    "        # Compute contrasts for each condition vs baseline\n",
    "        for contrast_id, contrast_val in contrasts.items():\n",
    "            contrast = compute_contrast(labels, estimates, contrast_val)\n",
    "            # Compute Z-map\n",
    "            z_map = contrast.z_score()\n",
    "            # z_map has shape (n_voxels,)\n",
    "            # Split z_map back to left and right hemispheres\n",
    "            z_map_L = z_map[:n_vertices_L]\n",
    "            z_map_R = z_map[n_vertices_L:]\n",
    "\n",
    "            # Create GIFTI DataArrays\n",
    "            z_map_L_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_L))\n",
    "            z_map_R_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_R))\n",
    "\n",
    "            # Create GIFTI images\n",
    "            z_map_img_L = nb.gifti.GiftiImage(darrays=[z_map_L_darray])\n",
    "            z_map_img_R = nb.gifti.GiftiImage(darrays=[z_map_R_darray])\n",
    "\n",
    "            # Save GIFTI images\n",
    "            z_map_file_L = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.L.func.gii')\n",
    "            z_map_file_R = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.R.func.gii')\n",
    "            nb.save(z_map_img_L, z_map_file_L)\n",
    "            nb.save(z_map_img_R, z_map_file_R)\n",
    "\n",
    "            print(f\"Contrast {contrast_id} for {subname}, run {run} completed and saved to {z_map_file_L} and {z_map_file_R}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
