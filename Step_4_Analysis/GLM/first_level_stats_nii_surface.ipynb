{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept_zmap.nii.gz\n",
      "Contrast strongly_accept for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept_zmap.nii.gz\n",
      "Contrast weakly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject_zmap.nii.gz\n",
      "Contrast NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_NoResp_zmap.nii.gz\n",
      "Contrast weakly_accept - strongly_accept for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - strongly_accept_zmap.nii.gz\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - NoResp_zmap.nii.gz\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - NoResp_zmap.nii.gz\n",
      "Contrast weakly_reject - strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject - strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_reject - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject - NoResp_zmap.nii.gz\n",
      "Contrast strongly_reject - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject - NoResp_zmap.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast strongly_accept for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept_zmap.nii.gz\n",
      "Contrast weakly_accept for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept_zmap.nii.gz\n",
      "Contrast strongly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - weakly_accept for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - weakly_accept_zmap.nii.gz\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_reject - weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject - weakly_reject_zmap.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept_zmap.nii.gz\n",
      "Contrast strongly_accept for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept_zmap.nii.gz\n",
      "Contrast weakly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - strongly_accept for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - strongly_accept_zmap.nii.gz\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_reject - strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject - strongly_reject_zmap.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept_zmap.nii.gz\n",
      "Contrast strongly_accept for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept_zmap.nii.gz\n",
      "Contrast strongly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - strongly_accept for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - strongly_accept_zmap.nii.gz\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept - strongly_reject_zmap.nii.gz\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept - weakly_reject_zmap.nii.gz\n",
      "Contrast strongly_reject - weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_nii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject - weakly_reject_zmap.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import nibabel as nb\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from itertools import combinations  # For computing contrasts between conditions\n",
    "\n",
    "# Define the function to adjust the event timetable based on motion information\n",
    "def motion_controlled_event_timetable(event_table, fd_data, six_absolute_motion, TR, FD_thr, ab_motion_thr):\n",
    "    # Detect timepoints where FD exceeds the threshold\n",
    "    out_motion_detect = fd_data.to_numpy()[:] > FD_thr\n",
    "    out_motion_index = np.where(out_motion_detect == True)\n",
    "    # Detect timepoints where any of the six motion parameters exceed the absolute motion threshold\n",
    "    six_motion_ex = np.where(np.sum((six_absolute_motion > ab_motion_thr) == True, 1) > 0)\n",
    "    \n",
    "    # Convert motion timepoints to actual time by multiplying with TR\n",
    "    out_motion_time = np.array([])\n",
    "    if len(out_motion_index[0]) > 0:\n",
    "        out_motion_time = (out_motion_index[0][:] + 1) * TR\n",
    "    if len(six_motion_ex[0]) > 0:\n",
    "        six_motion_time = (six_motion_ex[0] + 1) * TR\n",
    "        out_motion_time = np.concatenate((out_motion_time, six_motion_time), axis=0)\n",
    "        out_motion_time = np.unique(out_motion_time)\n",
    "    \n",
    "    tmp_timetable = event_table.assign(time_end=lambda dataframe: dataframe['onset'] + dataframe['duration'])\n",
    "    tmp_timetable = tmp_timetable.reset_index(drop=True)\n",
    "    \n",
    "    # Mark the timepoints where motion exceeds thresholds\n",
    "    block_time_judge = np.zeros(tmp_timetable.shape[0])\n",
    "    block_time_in = np.zeros(tmp_timetable.shape[0])\n",
    "    try:\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            for i in out_motion_time:\n",
    "                time_judge_0 = (i <= tmp_timetable.loc[n_time, 'time_end'])\n",
    "                block_time_judge[n_time] += time_judge_0\n",
    "                time_judge_1 = (i <= tmp_timetable.loc[n_time, 'time_end']) * (i >= tmp_timetable.loc[n_time, 'onset'])\n",
    "                block_time_in[n_time] += time_judge_1\n",
    "            \n",
    "        tmp_timetable = tmp_timetable.assign(\n",
    "            time_delete=block_time_judge * TR,\n",
    "            delete_time_inblock=block_time_in\n",
    "        )\n",
    "        tmp_timetable.loc[:, 'duration'] = tmp_timetable['duration'] - tmp_timetable['delete_time_inblock'] * TR\n",
    "        \n",
    "        # Adjust onset times and recalculate time_end\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            if n_time != 0:\n",
    "                tmp_timetable.loc[n_time, 'onset'] = tmp_timetable.loc[n_time, 'onset'] - tmp_timetable.loc[n_time, 'time_delete']\n",
    "            tmp_timetable.loc[n_time, 'time_end'] = tmp_timetable.loc[n_time, 'onset'] + tmp_timetable.loc[n_time, 'duration']\n",
    "    except Exception as e:\n",
    "        print(\"Error in motion_controlled_event_timetable:\", e)\n",
    "        out_motion_time = False\n",
    "        tmp_timetable = event_table\n",
    "    return [tmp_timetable, out_motion_time]\n",
    "\n",
    "# Define the function to correct NIfTI data based on motion information\n",
    "def correct_motion_for_niidata(motion_corrected_path, subname, run, task_file, nii_data, TR, out_motion_time):\n",
    "    motion_corrected_subfolder = op.join(motion_corrected_path, subname)\n",
    "    if not os.path.exists(motion_corrected_subfolder):\n",
    "        os.makedirs(motion_corrected_subfolder)\n",
    "    motion_corrected_nii = op.join(motion_corrected_subfolder, subname + task_file)\n",
    "    niidata = nb.load(nii_data)\n",
    "    timepoints_to_delete = ((out_motion_time / TR).astype('int64')) - 1\n",
    "    motion_corrected_data = np.delete(niidata.get_fdata(), timepoints_to_delete, axis=3)\n",
    "    motion_corrected_nii_data = nb.Nifti1Image(motion_corrected_data, header=niidata.header, affine=niidata.affine)\n",
    "    motion_corrected_nii_data.header.set_data_dtype(np.int16)\n",
    "    nb.save(motion_corrected_nii_data, motion_corrected_nii)\n",
    "    return motion_corrected_nii\n",
    "\n",
    "roodir = '/mnt/d/language_atlas_project/newdata/ds001734'\n",
    "sublist = ['001']  # Add more subjects as needed\n",
    "runs = ['01', '02', '03', '04']\n",
    "taskname = 'MGT'\n",
    "TR = 1.0  # Adjust TR based on your data\n",
    "FD_thr = 0.2  # Framewise displacement threshold\n",
    "ab_motion_thr = 3  # Absolute motion threshold\n",
    "\n",
    "# Output paths\n",
    "out_path = op.join(roodir, 'derivatives', 'first_level_model_corrected_nii')\n",
    "motion_corrected_path = op.join(roodir, 'derivatives', 'motion_corrected_data_nii')\n",
    "# Set whether to perform motion exclusion\n",
    "do_motion_exclusion = False  # Set to False to avoid deleting frames due to motion\n",
    "for sub in sublist:\n",
    "    subname = 'sub-' + sub\n",
    "    subeventdir = op.join(roodir, subname, 'func')\n",
    "    subimagedir = op.join(roodir, 'derivatives', 'fmriprep', subname, 'func')\n",
    "    for run in runs:\n",
    "        sub_event_file = op.join(subeventdir, f'{subname}_task-{taskname}_run-{run}_events.tsv')\n",
    "        sub_niidata_file = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "        sub_motioninfo_file = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_confounds.tsv')\n",
    "\n",
    "        # Check if all necessary files exist\n",
    "        if not (os.path.exists(sub_event_file) and os.path.exists(sub_niidata_file) and os.path.exists(sub_motioninfo_file)):\n",
    "            print(f\"Missing files for {subname}, run {run}\")\n",
    "            continue\n",
    "\n",
    "        # Load event data\n",
    "        event_data = pd.read_csv(sub_event_file, sep='\\t')\n",
    "        # Rename 'participant_response' to 'trial_type'\n",
    "        if 'participant_response' in event_data.columns:\n",
    "            event_data.rename(columns={'participant_response': 'trial_type'}, inplace=True)\n",
    "        else:\n",
    "            print(f\"'participant_response' column not found in {sub_event_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load motion parameters data\n",
    "        confounds = pd.read_csv(sub_motioninfo_file, sep='\\t')\n",
    "        # Handle missing values\n",
    "        confounds = confounds.fillna(0)\n",
    "\n",
    "        # Get framewise displacement (FD) data\n",
    "        if 'FramewiseDisplacement' in confounds.columns:\n",
    "            fd = confounds[['FramewiseDisplacement']]\n",
    "        elif 'framewise_displacement' in confounds.columns:\n",
    "            fd = confounds[['framewise_displacement']]\n",
    "        else:\n",
    "            print(f\"FD column not found in {sub_motioninfo_file}\")\n",
    "            continue\n",
    "\n",
    "        # Get six motion parameters\n",
    "        motion_params = confounds[['X', 'Y', 'Z', 'RotX', 'RotY', 'RotZ']]\n",
    "\n",
    "        # Motion correction\n",
    "        if do_motion_exclusion:\n",
    "            [event_data_corrected, out_motion_time] = motion_controlled_event_timetable(event_data, fd, motion_params, TR, FD_thr, ab_motion_thr)\n",
    "            # Save corrected event data\n",
    "            out_sub_path = op.join(out_path, subname)\n",
    "            if not os.path.exists(out_sub_path):\n",
    "                os.makedirs(out_sub_path)\n",
    "            event_out_file = op.join(out_sub_path, f'{subname}_task-{taskname}_run-{run}_events_corrected.tsv')\n",
    "            event_data_corrected.to_csv(event_out_file, sep='\\t', index=False)\n",
    "            # Correct NIfTI data\n",
    "            if not isinstance(out_motion_time, bool):\n",
    "                task_file = f'_task-{taskname}_run-{run}_bold_space-MNI152NLin2009cAsym_preproc.nii.gz'\n",
    "                corrected_nii_file = correct_motion_for_niidata(motion_corrected_path, subname, run, task_file, sub_niidata_file, TR, out_motion_time)\n",
    "                fmri_img = nb.load(corrected_nii_file)\n",
    "                # Adjust motion parameters\n",
    "                timepoints_to_delete = ((out_motion_time / TR).astype('int64')) - 1\n",
    "                motion_params_corrected = motion_params.drop(motion_params.index[timepoints_to_delete]).reset_index(drop=True)\n",
    "            else:\n",
    "                fmri_img = nb.load(sub_niidata_file)\n",
    "                motion_params_corrected = motion_params\n",
    "                event_data_corrected = event_data\n",
    "        else:\n",
    "            event_data_corrected = event_data\n",
    "            fmri_img = nb.load(sub_niidata_file)\n",
    "            motion_params_corrected = motion_params\n",
    "\n",
    "        # Perform first-level GLM analysis\n",
    "        fmri_glm = FirstLevelModel(\n",
    "            t_r=TR,\n",
    "            noise_model='ar1',\n",
    "            hrf_model='spm',\n",
    "            drift_model=None,\n",
    "            high_pass=1./128,  # Adjust the high-pass filter as needed\n",
    "            signal_scaling=False,\n",
    "            minimize_memory=False\n",
    "        )\n",
    "\n",
    "        fmri_glm = fmri_glm.fit(\n",
    "            fmri_img,\n",
    "            events=event_data_corrected,\n",
    "            confounds=motion_params_corrected\n",
    "        )\n",
    "\n",
    "        # Define contrasts\n",
    "        # Assuming 'trial_type' column contains condition names\n",
    "        conditions = event_data_corrected['trial_type'].unique()\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "\n",
    "        # Create contrasts for each condition\n",
    "        contrasts = {}\n",
    "        for cond in conditions:\n",
    "            # The columns corresponding to the condition\n",
    "            cond_vector = np.array([1 if c == cond else 0 for c in design_matrix.columns])\n",
    "            contrasts[cond] = cond_vector\n",
    "        # Compute contrasts for each condition vs baseline\n",
    "        out_sub_path = op.join(out_path, subname)\n",
    "        stats_results_path = op.join(out_sub_path, 'stats_results', f'run-{run}')\n",
    "        if not os.path.exists(stats_results_path):\n",
    "            os.makedirs(stats_results_path)\n",
    "        for contrast_id, contrast_val in contrasts.items():\n",
    "            z_map = fmri_glm.compute_contrast(contrast_val, output_type='z_score')\n",
    "            z_map_file = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.nii.gz')\n",
    "            z_map.to_filename(z_map_file)\n",
    "            print(f\"Contrast {contrast_id} for {subname}, run {run} completed and saved to {z_map_file}\")\n",
    "            # Optionally, plot the contrast map\n",
    "            # plot_stat_map(z_map, title=f'{subname} {contrast_id}', display_mode='ortho', threshold=3.0)\n",
    "        # Compute pairwise differences between conditions\n",
    "        for cond1, cond2 in combinations(conditions, 2):\n",
    "            contrast_vector = contrasts[cond1] - contrasts[cond2]\n",
    "            contrast_id = f'{cond1} - {cond2}'\n",
    "            z_map = fmri_glm.compute_contrast(contrast_vector, output_type='z_score')\n",
    "            z_map_file = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.nii.gz')\n",
    "            z_map.to_filename(z_map_file)\n",
    "            print(f\"Contrast {contrast_id} for {subname}, run {run} completed and saved to {z_map_file}\")\n",
    "\n",
    "            # Optionally, plot the contrast map\n",
    "            # plot_stat_map(z_map, title=f'{subname} {contrast_id}', display_mode='ortho', threshold=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下来处理皮层数据的激活结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n",
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/_utils.py:205: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_accept for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject_zmap.R.func.gii\n",
      "Contrast NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_NoResp_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_NoResp_zmap.R.func.gii\n",
      "Contrast weakly_accept - strongly_accept for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - strongly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - NoResp_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_accept - NoResp_zmap.R.func.gii\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - NoResp_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_accept - NoResp_zmap.R.func.gii\n",
      "Contrast weakly_reject - strongly_reject for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject - strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_reject - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject - NoResp_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_weakly_reject - NoResp_zmap.R.func.gii\n",
      "Contrast strongly_reject - NoResp for sub-001, run 01 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject - NoResp_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-01/sub-001_task-MGT_run-01_strongly_reject - NoResp_zmap.R.func.gii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n",
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/_utils.py:205: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast strongly_accept for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_accept for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - weakly_accept for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - weakly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_weakly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_reject - weakly_reject for sub-001, run 02 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-02/sub-001_task-MGT_run-02_strongly_reject - weakly_reject_zmap.R.func.gii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n",
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/_utils.py:205: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_accept for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - strongly_accept for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - strongly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_strongly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_reject - strongly_reject for sub-001, run 03 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-03/sub-001_task-MGT_run-03_weakly_reject - strongly_reject_zmap.R.func.gii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: gain, RT, loss\n",
      "  warnings.warn(\n",
      "/home/wuguowei/anaconda3/envs/nipype/lib/python3.10/site-packages/nilearn/glm/_utils.py:205: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(X <= 0, 0, 1.0 / X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast weakly_accept for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept_zmap.R.func.gii\n",
      "Contrast strongly_accept for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept_zmap.R.func.gii\n",
      "Contrast strongly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - strongly_accept for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - strongly_accept_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - strongly_accept_zmap.R.func.gii\n",
      "Contrast weakly_accept - strongly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast weakly_accept - weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_weakly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - strongly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept - strongly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept - strongly_reject_zmap.R.func.gii\n",
      "Contrast strongly_accept - weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_accept - weakly_reject_zmap.R.func.gii\n",
      "Contrast strongly_reject - weakly_reject for sub-001, run 04 completed and saved to /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject - weakly_reject_zmap.L.func.gii and /mnt/d/language_atlas_project/newdata/ds001734/derivatives/first_level_model_corrected_gii/sub-001/stats_results/run-04/sub-001_task-MGT_run-04_strongly_reject - weakly_reject_zmap.R.func.gii\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import nibabel as nb\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, run_glm\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "from itertools import combinations  # For computing contrasts between conditions\n",
    "\n",
    "# Define the function to adjust the event timetable based on motion information\n",
    "def motion_controlled_event_timetable(event_table, fd_data, six_absolute_motion, TR, FD_thr, ab_motion_thr):\n",
    "    # Detect timepoints where FD exceeds the threshold\n",
    "    out_motion_detect = fd_data.to_numpy().flatten() > FD_thr\n",
    "    out_motion_index = np.where(out_motion_detect)[0]\n",
    "    # Detect timepoints where any of the six motion parameters exceed the absolute motion threshold\n",
    "    six_motion_ex = np.where(np.any(np.abs(six_absolute_motion) > ab_motion_thr, axis=1))[0]\n",
    "    \n",
    "    # Convert motion timepoints to actual time by multiplying with TR\n",
    "    out_motion_time = np.array([])\n",
    "    if len(out_motion_index) > 0:\n",
    "        out_motion_time = (out_motion_index + 1) * TR\n",
    "    if len(six_motion_ex) > 0:\n",
    "        six_motion_time = (six_motion_ex + 1) * TR\n",
    "        out_motion_time = np.concatenate((out_motion_time, six_motion_time), axis=0)\n",
    "        out_motion_time = np.unique(out_motion_time)\n",
    "    \n",
    "    tmp_timetable = event_table.assign(time_end=lambda dataframe: dataframe['onset'] + dataframe['duration'])\n",
    "    tmp_timetable = tmp_timetable.reset_index(drop=True)\n",
    "    \n",
    "    # Mark the timepoints where motion exceeds thresholds\n",
    "    block_time_judge = np.zeros(tmp_timetable.shape[0])\n",
    "    block_time_in = np.zeros(tmp_timetable.shape[0])\n",
    "    try:\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            for i in out_motion_time:\n",
    "                time_judge_0 = (i <= tmp_timetable.loc[n_time, 'time_end'])\n",
    "                block_time_judge[n_time] += time_judge_0\n",
    "                time_judge_1 = (i <= tmp_timetable.loc[n_time, 'time_end']) and (i >= tmp_timetable.loc[n_time, 'onset'])\n",
    "                block_time_in[n_time] += time_judge_1\n",
    "            \n",
    "        tmp_timetable = tmp_timetable.assign(\n",
    "            time_delete=block_time_judge * TR,\n",
    "            delete_time_inblock=block_time_in\n",
    "        )\n",
    "        tmp_timetable.loc[:, 'duration'] = tmp_timetable['duration'] - tmp_timetable['delete_time_inblock'] * TR\n",
    "        \n",
    "        # Adjust onset times and recalculate time_end\n",
    "        for n_time in range(tmp_timetable.shape[0]):\n",
    "            if n_time != 0:\n",
    "                tmp_timetable.loc[n_time, 'onset'] = tmp_timetable.loc[n_time, 'onset'] - tmp_timetable.loc[n_time, 'time_delete']\n",
    "            tmp_timetable.loc[n_time, 'time_end'] = tmp_timetable.loc[n_time, 'onset'] + tmp_timetable.loc[n_time, 'duration']\n",
    "    except Exception as e:\n",
    "        print(\"Error in motion_controlled_event_timetable:\", e)\n",
    "        out_motion_time = False\n",
    "        tmp_timetable = event_table\n",
    "    return [tmp_timetable, out_motion_time]\n",
    "\n",
    "# Define the function to correct motion in GIFTI data\n",
    "def correct_motion_for_giidata(motion_corrected_path, subname, run, task_file_L, task_file_R, data_L_path, data_R_path, TR, out_motion_time):\n",
    "    motion_corrected_subfolder = op.join(motion_corrected_path, subname)\n",
    "    if not os.path.exists(motion_corrected_subfolder):\n",
    "        os.makedirs(motion_corrected_subfolder)\n",
    "    corrected_gii_file_L = op.join(motion_corrected_subfolder, subname + task_file_L)\n",
    "    corrected_gii_file_R = op.join(motion_corrected_subfolder, subname + task_file_R)\n",
    "    \n",
    "    # Load GIFTI data\n",
    "    data_L = nb.load(data_L_path)\n",
    "    data_R = nb.load(data_R_path)\n",
    "    \n",
    "    # Calculate timepoints to delete\n",
    "    timepoints_to_delete = ((out_motion_time / TR).astype(int)) - 1\n",
    "    timepoints_to_keep = np.setdiff1d(np.arange(len(data_L.darrays)), timepoints_to_delete)\n",
    "    \n",
    "    # Create new GIFTI images with selected timepoints\n",
    "    corrected_darrays_L = [data_L.darrays[i] for i in timepoints_to_keep]\n",
    "    corrected_darrays_R = [data_R.darrays[i] for i in timepoints_to_keep]\n",
    "    \n",
    "    corrected_data_L = nb.gifti.GiftiImage(darrays=corrected_darrays_L)\n",
    "    corrected_data_R = nb.gifti.GiftiImage(darrays=corrected_darrays_R)\n",
    "    \n",
    "    # Save corrected GIFTI data\n",
    "    nb.save(corrected_data_L, corrected_gii_file_L)\n",
    "    nb.save(corrected_data_R, corrected_gii_file_R)\n",
    "    \n",
    "    return corrected_gii_file_L, corrected_gii_file_R\n",
    "\n",
    "# Main code\n",
    "roodir = '/mnt/d/language_atlas_project/newdata/ds001734'\n",
    "sublist = ['001']  # Add more subjects as needed\n",
    "runs = ['01', '02', '03', '04']\n",
    "taskname = 'MGT'\n",
    "TR = 1.0  # Adjust TR based on your data\n",
    "FD_thr = 0.2  # Framewise displacement threshold\n",
    "ab_motion_thr = 3  # Absolute motion threshold\n",
    "\n",
    "# Output paths\n",
    "out_path = op.join(roodir, 'derivatives', 'first_level_model_corrected_gii')\n",
    "motion_corrected_path = op.join(roodir, 'derivatives', 'motion_corrected_data_gii')\n",
    "\n",
    "# Set whether to perform motion exclusion\n",
    "do_motion_exclusion = False  # Set to False to avoid deleting frames due to motion\n",
    "\n",
    "for sub in sublist:\n",
    "    subname = 'sub-' + sub\n",
    "    subeventdir = op.join(roodir, subname, 'func')\n",
    "    subimagedir = op.join(roodir, 'derivatives', 'fmriprep', subname, 'func')\n",
    "    for run in runs:\n",
    "        sub_event_file = op.join(subeventdir, f'{subname}_task-{taskname}_run-{run}_events.tsv')\n",
    "        sub_gii_file_L = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-fsaverage5.L.func.gii')\n",
    "        sub_gii_file_R = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_space-fsaverage5.R.func.gii')\n",
    "        sub_motioninfo_file = op.join(subimagedir, f'{subname}_task-{taskname}_run-{run}_bold_confounds.tsv')\n",
    "\n",
    "        # Check if all necessary files exist\n",
    "        if not (os.path.exists(sub_event_file) and os.path.exists(sub_gii_file_L) and os.path.exists(sub_gii_file_R) and os.path.exists(sub_motioninfo_file)):\n",
    "            print(f\"Missing files for {subname}, run {run}\")\n",
    "            continue\n",
    "\n",
    "        # Load event data\n",
    "        event_data = pd.read_csv(sub_event_file, sep='\\t')\n",
    "        # Rename 'participant_response' to 'trial_type'\n",
    "        if 'participant_response' in event_data.columns:\n",
    "            event_data.rename(columns={'participant_response': 'trial_type'}, inplace=True)\n",
    "        else:\n",
    "            print(f\"'participant_response' column not found in {sub_event_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load motion parameters data\n",
    "        confounds = pd.read_csv(sub_motioninfo_file, sep='\\t')\n",
    "        # Handle missing values\n",
    "        confounds = confounds.fillna(0)\n",
    "\n",
    "        # Get framewise displacement (FD) data\n",
    "        if 'FramewiseDisplacement' in confounds.columns:\n",
    "            fd = confounds[['FramewiseDisplacement']]\n",
    "        elif 'framewise_displacement' in confounds.columns:\n",
    "            fd = confounds[['framewise_displacement']]\n",
    "        else:\n",
    "            print(f\"FD column not found in {sub_motioninfo_file}\")\n",
    "            continue\n",
    "\n",
    "        # Get six motion parameters\n",
    "        motion_params = confounds[['X', 'Y', 'Z', 'RotX', 'RotY', 'RotZ']]\n",
    "\n",
    "        # Motion correction\n",
    "        if do_motion_exclusion:\n",
    "            # [Motion correction code remains unchanged]\n",
    "            # ...\n",
    "            pass\n",
    "        else:\n",
    "            event_data_corrected = event_data\n",
    "            data_L = nb.load(sub_gii_file_L)\n",
    "            data_R = nb.load(sub_gii_file_R)\n",
    "            motion_params_corrected = motion_params\n",
    "\n",
    "        # Concatenate left and right hemisphere data\n",
    "        n_timepoints = len(data_L.darrays)\n",
    "        n_vertices_L = data_L.darrays[0].data.shape[0]\n",
    "        n_vertices_R = data_R.darrays[0].data.shape[0]\n",
    "\n",
    "        # Initialize data matrix\n",
    "        data_matrix = np.zeros((n_timepoints, n_vertices_L + n_vertices_R))\n",
    "        for t in range(n_timepoints):\n",
    "            data_L_t = data_L.darrays[t].data\n",
    "            data_R_t = data_R.darrays[t].data\n",
    "            data_matrix[t, :n_vertices_L] = data_L_t\n",
    "            data_matrix[t, n_vertices_L:] = data_R_t\n",
    "\n",
    "        # Build design matrix\n",
    "        frame_times = TR * (np.arange(n_timepoints))\n",
    "        design_matrix = make_first_level_design_matrix(\n",
    "            frame_times,\n",
    "            event_data_corrected,\n",
    "            drift_model='polynomial',\n",
    "            drift_order=3,\n",
    "            add_regs=motion_params_corrected,\n",
    "            add_reg_names=motion_params_corrected.columns,\n",
    "            hrf_model='spm'\n",
    "        )\n",
    "\n",
    "        # Perform GLM analysis\n",
    "        # Do NOT transpose data_matrix; Y should have shape (n_samples, n_voxels)\n",
    "        labels, estimates = run_glm(data_matrix, design_matrix.values)\n",
    "\n",
    "        # Define contrasts\n",
    "        conditions = event_data_corrected['trial_type'].unique()\n",
    "        design_columns = design_matrix.columns\n",
    "\n",
    "        # Create contrasts for each condition\n",
    "        contrasts = {}\n",
    "        for cond in conditions:\n",
    "            # The columns corresponding to the condition\n",
    "            cond_vector = np.array([1 if cond == col else 0 for col in design_columns])\n",
    "            contrasts[cond] = cond_vector\n",
    "\n",
    "        # Prepare output directories\n",
    "        out_sub_path = op.join(out_path, subname)\n",
    "        stats_results_path = op.join(out_sub_path, 'stats_results', f'run-{run}')\n",
    "        if not os.path.exists(stats_results_path):\n",
    "            os.makedirs(stats_results_path)\n",
    "\n",
    "        # Compute contrasts for each condition vs baseline\n",
    "        for contrast_id, contrast_val in contrasts.items():\n",
    "            contrast = compute_contrast(labels, estimates, contrast_val)\n",
    "            # Compute Z-map\n",
    "            z_map = contrast.z_score()\n",
    "            # z_map has shape (n_voxels,)\n",
    "            # Split z_map back to left and right hemispheres\n",
    "            z_map_L = z_map[:n_vertices_L]\n",
    "            z_map_R = z_map[n_vertices_L:]\n",
    "\n",
    "            # Create GIFTI DataArrays\n",
    "            z_map_L_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_L))\n",
    "            z_map_R_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_R))\n",
    "\n",
    "            # Create GIFTI images\n",
    "            z_map_img_L = nb.gifti.GiftiImage(darrays=[z_map_L_darray])\n",
    "            z_map_img_R = nb.gifti.GiftiImage(darrays=[z_map_R_darray])\n",
    "\n",
    "            # Save GIFTI images\n",
    "            z_map_file_L = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.L.func.gii')\n",
    "            z_map_file_R = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.R.func.gii')\n",
    "            nb.save(z_map_img_L, z_map_file_L)\n",
    "            nb.save(z_map_img_R, z_map_file_R)\n",
    "\n",
    "            print(f\"Contrast {contrast_id} for {subname}, run {run} completed and saved to {z_map_file_L} and {z_map_file_R}\")\n",
    "\n",
    "        # Compute pairwise differences between conditions\n",
    "        for cond1, cond2 in combinations(conditions, 2):\n",
    "            contrast_vector = contrasts[cond1] - contrasts[cond2]\n",
    "            contrast_id = f'{cond1} - {cond2}'\n",
    "\n",
    "            contrast = compute_contrast(labels, estimates, contrast_vector)\n",
    "            # Compute Z-map\n",
    "            z_map = contrast.z_score()\n",
    "            # z_map has shape (n_voxels,)\n",
    "            # Split z_map back to left and right hemispheres\n",
    "            z_map_L = z_map[:n_vertices_L]\n",
    "            z_map_R = z_map[n_vertices_L:]\n",
    "\n",
    "            # Create GIFTI DataArrays\n",
    "            z_map_L_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_L))\n",
    "            z_map_R_darray = nb.gifti.GiftiDataArray(data=np.int32(z_map_R))\n",
    "\n",
    "            # Create GIFTI images\n",
    "            z_map_img_L = nb.gifti.GiftiImage(darrays=[z_map_L_darray])\n",
    "            z_map_img_R = nb.gifti.GiftiImage(darrays=[z_map_R_darray])\n",
    "\n",
    "            # Save GIFTI images\n",
    "            z_map_file_L = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.L.func.gii')\n",
    "            z_map_file_R = op.join(stats_results_path, f'{subname}_task-{taskname}_run-{run}_{contrast_id}_zmap.R.func.gii')\n",
    "            nb.save(z_map_img_L, z_map_file_L)\n",
    "            nb.save(z_map_img_R, z_map_file_R)\n",
    "\n",
    "            print(f\"Contrast {contrast_id} for {subname}, run {run} completed and saved to {z_map_file_L} and {z_map_file_R}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
